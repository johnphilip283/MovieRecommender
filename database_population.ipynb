{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Population\n",
    "\n",
    "Here, we are going to take the augmented dataset that we created in the previous Jupyter notebook, and store it in a relational database. We put the database in 3rd normal form, in order to reduce redundancy, and enhance data integrity. We use the sqlite3 Python package, which allows for lightweight and in-memory relational database creation, which is the most natural form for this database to take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are in the process of writing the database, we can create a virtual connection to an in-memory database, and then dump out the contents of the database to a file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(':memory:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will just be some utility functions that allow us to more easily add rows into our database later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_for_join_table(type, movie_id, val_id):\n",
    "    \n",
    "    # Returns the appropriately formatted query for populating the join tables between movies and other tables.\n",
    "    return \"\"\"\n",
    "           insert into movie_has_{0} (movie_id, {0}_id) values ({1}, {2})\n",
    "           \"\"\".format(type, movie_id, val_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query_string, conn=conn):\n",
    "    \n",
    "    # Returns the results of a particular SQL query.\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query_string)\n",
    "\n",
    "    return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_from_name(name, table):\n",
    "    \n",
    "    # Return the id associated with a particular name from a particular table.\n",
    "    return query('select {0}_id from {0} where name=\"{1}\"'.format(table, name.strip().title()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_name_to_table(name, table):\n",
    "    \n",
    "    # Insert the given name into the given table, and for convenience, return the id associated with the newly created name.\n",
    "    query('insert into {0} (name) values (\"{1}\")'.format(table, name.strip().title()))\n",
    "\n",
    "    return id_from_name(name, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(val, table):\n",
    "    \n",
    "    # If the value isn't in the table, add it, and then return the ID associated with it.\n",
    "    val = val.lower().title()\n",
    "    \n",
    "    ids = id_from_name(val, table)\n",
    "\n",
    "    if len(ids) == 0:\n",
    "\n",
    "        # val doesn't exist yet, so insert them, then get back their id\n",
    "        ids = add_name_to_table(val, table)\n",
    "\n",
    "    # We should be guaranteed to have one entry in ids\n",
    "    assert len(ids) == 1\n",
    "\n",
    "    return int(ids[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to set up the database, we declare the schema of the database in the movie.sql file. Running that script populates the database with the appropriate tables that we can then insert into as we iterate through the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the main database, loading in the table schema\n",
    "with open(\"movie.sql\") as f:\n",
    "    script = f.read()\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.executescript(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell will allow you to see the movie.sql file contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat movie.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insertion Process\n",
    "1. First, read the CSV into a pandas dataframe.\n",
    "2. Second, replace all of the NaNs with empty strings.\n",
    "3. Since the index of each row is unique, we can use that to represent each movie_id in the database.\n",
    "4. Strip all of the appropriate fields of whitespace, canonicalize them by titling them, and then format the query appropriately.\n",
    "5. For each of the fields that can have multiple values per row, independently insert each of the values into the correct table and its corresponding join table.\n",
    "6. Since each of the ratings (metacritic, rotten tomatoes, and IMDB) are on different scales, normalize them before we enter them into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start reading through the big CSV\n",
    "df = pd.read_csv(\"final.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    row = {key: (str(val).replace('\"', '') if str(val) != \"nan\" else \"\") for key, val in dict(row).items()}\n",
    "\n",
    "    movie_id = index + 1\n",
    "\n",
    "    try:\n",
    "        INSERT_MOVIE_QUERY = 'insert into movie (movie_id, origin, year, title, wiki_link, plot, imdb_rating, imdb_votes, rated, rotten_tomato_rating, metacritic_rating) values ({}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {})'.format(movie_id,\n",
    "                                       '\"{}\"'.format(row[\"Origin/Ethnicity\"].strip().title()) if row[\"Origin/Ethnicity\"] else \"NULL\",\n",
    "                                       int(row[\"Release Year\"]) if row[\"Release Year\"] else \"NULL\",\n",
    "                                       '\"{}\"'.format(row[\"Title\"].strip().title()) if row[\"Title\"] else \"NULL\",\n",
    "                                       '\"{}\"'.format(row[\"Wiki Page\"]) if row[\"Wiki Page\"] else \"NULL\",\n",
    "                                       '\"{}\"'.format(row[\"Plot\"].strip().capitalize()) if row[\"Plot\"] else \"NULL\",\n",
    "                                       float(row[\"imdbRating\"]) / 10 if row[\"imdbRating\"] else \"NULL\",\n",
    "                                       row[\"imdbVotes\"].replace(\",\", \"\") if row[\"imdbVotes\"] else \"NULL\",\n",
    "                                       '\"{}\"'.format(row[\"Rated\"].strip()) if row[\"Rated\"] else \"NULL\",\n",
    "                                       int(row[\"Rotten Tomatoes\"]) / 100 if row[\"Rotten Tomatoes\"] else \"NULL\",\n",
    "                                       int(row[\"Metacritic\"]) / 100 if row[\"Metacritic\"] else \"NULL\")\n",
    "    except ValueError as e:\n",
    "\n",
    "        # There is a strange row in the dataset that just has the header names repeated again. If we run into this,\n",
    "        # then move onto the next row. If that isn't the problem, then raise the exception again.\n",
    "        if row[\"Release Year\"] == \"Release Year\":\n",
    "            continue\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    query(INSERT_MOVIE_QUERY)\n",
    "\n",
    "    for label, table in [(\"Director\", \"director\"), (\"Cast\", \"actor\"), (\"Genre\", \"genre\")]:\n",
    "        \n",
    "        # If there are values for this label,\n",
    "        if row[label]:\n",
    "            \n",
    "            # Get a list of all of these values\n",
    "            val_list = row[label].strip().split(',')\n",
    "            for val in val_list:\n",
    "                \n",
    "                # If the value is a valid one,\n",
    "                if val:\n",
    "                    \n",
    "                    # Add it to the appropriate table.\n",
    "                    query(query_for_join_table(table, movie_id, get_id(val, table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our database now holds all of the relevant data from the CSVs, so we can dump it out to a SQL file that we can later reload into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dump.sql', 'w') as f:\n",
    "    for line in conn.iterdump():\n",
    "        f.write('%s\\n' % line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
